{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "import os\n",
    "import json\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df10 = pd.read_csv(\"Ref10_LMI.csv\", index_col = 0, dtype = {'SHP_BOROUGH': object, 'SHP_CENSUS_TRACT': object, 'SHP_CENSUS_BLOCK': object, 'Geo_COUNTY': object} )\n",
    "df11 = pd.read_csv(\"Ref11_LMI.csv\", index_col = 0, dtype = {'SHP_BOROUGH': object, 'SHP_CENSUS_TRACT': object, 'SHP_CENSUS_BLOCK': object, 'Geo_COUNTY': object} )\n",
    "df12 = pd.read_csv(\"Ref12_LMI.csv\", index_col = 0, dtype = {'SHP_BOROUGH': object, 'SHP_CENSUS_TRACT': object, 'SHP_CENSUS_BLOCK': object, 'Geo_COUNTY': object} )\n",
    "df13 = pd.read_csv(\"Ref13_LMI.csv\", index_col = 0, dtype = {'SHP_BOROUGH': object, 'SHP_CENSUS_TRACT': object, 'SHP_CENSUS_BLOCK': object, 'Geo_COUNTY': object} )\n",
    "df14 = pd.read_csv(\"Ref14_LMI.csv\", index_col = 0, dtype = {'SHP_BOROUGH': object, 'SHP_CENSUS_TRACT': object, 'SHP_CENSUS_BLOCK': object, 'Geo_COUNTY': object} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = [df10, df11, df12, df13, df14]\n",
    "\n",
    "for df in files:\n",
    "    df['count'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df10_grouped = df10.groupby(['PRMSIC', 'PRMSICD', 'PNACODE', 'PNATITL', 'Geo_COUNTY', 'SHP_BOROUGH', 'SHP_CENSUS_TRACT', 'lmi_ct'])['EMPSDT', 'SLSVDT', 'count'].agg(['sum', 'median']).reset_index()\n",
    "df11_grouped = df11.groupby(['PRMSIC', 'SICD', 'PNACODE', 'PNATITL', 'Geo_COUNTY', 'SHP_BOROUGH', 'SHP_CENSUS_TRACT', 'lmi_ct'])['EMPSDT', 'SLSVDT', 'count'].agg(['sum', 'median']).reset_index()\n",
    "df12_grouped = df12.groupby(['PRMSIC', 'SICD', 'PNACODE', 'PNATITL', 'Geo_COUNTY', 'SHP_BOROUGH', 'SHP_CENSUS_TRACT', 'lmi_ct'])['EMPSDT', 'SLSVDT', 'count'].agg(['sum', 'median']).reset_index()\n",
    "df13_grouped = df13.groupby(['PRMSIC', 'SICD', 'PNACODE', 'PNATITL', 'Geo_COUNTY', 'SHP_BOROUGH', 'SHP_CENSUS_TRACT', 'lmi_ct'])['EMPSDT', 'SLSVDT', 'count'].agg(['sum', 'median']).reset_index()\n",
    "df14_grouped = df14.groupby(['PRMSIC', 'SICD', 'PNACODE', 'PNATITL', 'Geo_COUNTY', 'SHP_BOROUGH', 'SHP_CENSUS_TRACT', 'lmi_ct'])['EMPSDT', 'SLSVDT', 'count'].agg(['sum', 'median']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped_files = [df10_grouped, df11_grouped, df12_grouped, df13_grouped, df14_grouped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = ['PRMSIC', 'SICD', 'PNACODE', 'PNATITL', 'Geo_COUNTY', 'SHP_BOROUGH', 'SHP_CENSUS_TRACT', 'lmi_ct', \\\n",
    "        'EMPSDT_SUM', 'EMPSDT_MED', 'SLSVDT_SUM', 'SLSVDT_MED', 'count_SUM', 'count_MED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getNAICS(row):\n",
    "    code = str(row['PNACODE'])[0:2]\n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getNAICSLabel(row):\n",
    "    label = naicsCODES[row['NAICS']] \n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "naicsCODES = \\\n",
    "{'11': 'AGRICULTURE, FORESTRY, FISHING AND HUNTING',\n",
    " '21': 'MINING',\n",
    " '22': 'UTILITIES',\n",
    " '23': 'CONSTRUCTION',\n",
    " '31': 'MANUFACTURING',\n",
    " '32': 'MANUFACTURING',\n",
    " '33': 'MANUFACTURING',\n",
    " '42': 'WHOLESALE TRADE',\n",
    " '44': 'RETAIL TRADE',\n",
    " '45': 'RETAIL TRADE',\n",
    " '48': 'TRANSPORTATION AND WAREHOUSING',\n",
    " '49': 'TRANSPORTATION AND WAREHOUSING',\n",
    " '51': 'INFORMATION',\n",
    " '52': 'FINANCE AND INSURANCE',\n",
    " '53': 'REAL ESTATE RENTAL AND LEASING',\n",
    " '54': 'PROFESSIONAL, SCIENTIFIC, AND TECHNICAL SERVICES',\n",
    " '55': 'MANAGEMENT OF COMPANIES AND ENTERPRISES',\n",
    " '56': 'ADMINISTRATIVE AND SUPPORT AND WASTE MANAGEMENT AND REMEDIATION SERVICES',\n",
    " '61': 'EDUCATIONAL SERVICES',\n",
    " '62': 'HEALTH CARE AND SOCIAL ASSISTANCE',\n",
    " '71': 'ARTS, ENTERTAINMENT, AND RECREATION',\n",
    " '72': 'ACCOMMODATION AND FOOD SERVICES',\n",
    " '81': 'OTHER SERVICES (EXCEPT PUBLIC ADMINISTRATION)',\n",
    " '92': 'PUBLIC ADMINISTRATION',\n",
    " '99': 'UNCLASSIFIED'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for df in grouped_files:\n",
    "    df.columns = df.columns.droplevel(1)\n",
    "    df.columns = cols \n",
    "    del df['count_MED']\n",
    "    df.loc[:,'NAICS'] = df.apply(getNAICS, axis = 1)\n",
    "    df.loc[:,'NAICS_LABEL'] = df.apply(getNAICSLabel, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####don't use below code - no need to save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df10_grouped.to_csv(\"df10_grouped.csv\")\n",
    "df11_grouped.to_csv(\"df11_grouped.csv\")\n",
    "df12_grouped.to_csv(\"df12_grouped.csv\") \n",
    "df13_grouped.to_csv(\"df13_grouped.csv\")\n",
    "df14_grouped.to_csv(\"df14_grouped.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff_ref_census.csv  LMI_CT.csv     \u001b[0m\u001b[38;5;27mnyc_test5.tm2\u001b[0m/  \u001b[38;5;27mtest\u001b[0m/\r\n",
      "\u001b[38;5;27mgrouped_files\u001b[0m/       \u001b[38;5;27mmapping\u001b[0m/       nys_mi.csv      \u001b[38;5;27mzbp_just_nyc\u001b[0m/\r\n",
      "\u001b[38;5;9mgroupedfiles.zip\u001b[0m     \u001b[38;5;27mnybb_15b\u001b[0m/      \u001b[38;5;27mpython\u001b[0m/         \u001b[38;5;34mzipcodes.py\u001b[0m*\r\n",
      "\u001b[38;5;27mimages\u001b[0m/              \u001b[38;5;27mnycb2010_15b\u001b[0m/  README.md       zipcodes.pyc\r\n",
      "\u001b[38;5;27miPython_Notebooks\u001b[0m/   \u001b[38;5;27mnyct2010_15b\u001b[0m/  \u001b[38;5;27mRef_LMI\u001b[0m/        zips.csv\r\n",
      "\u001b[m"
     ]
    }
   ],
   "source": [
    "ls ../nyct2010_15b/nyct2010.shp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "boros = gp.GeoDataFrame.from_file(\"../nyct2010_15b/nyct2010.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####test drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df10_grouped[df10_grouped['SICD'] == 'BEAUTY SALONS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = pd.merge(df, boros[['BoroName', 'CT2010', 'NTAName', 'Shape_Area', 'geometry']], \\\n",
    "                  left_on = ['SHP_BOROUGH', 'SHP_CENSUS_TRACT'], right_on = ['BoroName', 'CT2010'])\n",
    "del result['BoroName']\n",
    "del result['CT2010']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Figure out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import shapefile\n",
    "from pyproj import Proj, transform \n",
    "from shapely.geometry import Polygon\n",
    "from shapely.geometry import MultiPolygon\n",
    "\n",
    "def convert(li):\n",
    "    f = 0.304800\n",
    "    inProj = Proj(init='epsg:2263')\n",
    "    outProj = Proj(init='epsg:4326')\n",
    "    x0,y0 = li[0]*f, li[1]*f\n",
    "    x2,y2 = transform(inProj,outProj,x0,y0)\n",
    "    \n",
    "    return (x2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def convertPolygon(list_of_points):\n",
    "#     polygon_points = [] \n",
    "#     for i in list_of_points:\n",
    "#         new_point = tuple(convert(i))\n",
    "#         polygon_points.append(new_point)\n",
    "#     return polygon_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# boros['geometry'][0].exterior.coords.xy[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convertCoordinates(row):\n",
    "    geo = row['geometry']\n",
    "    \n",
    "    try: \n",
    "        x = list(geo.exterior.coords)\n",
    "        new_list = [] \n",
    "    \n",
    "        for i in x:\n",
    "            new_list.append(convert(i))\n",
    "        \n",
    "        return Polygon(new_list)\n",
    "    \n",
    "    except: \n",
    "        x0 = list(geo[0].exterior.coords)\n",
    "        x1 = list(geo[1].exterior.coords) \n",
    "\n",
    "        new_list0 = []\n",
    "        new_list1 = []\n",
    "\n",
    "        for i in x0:\n",
    "            new_list0.append(convert(i))\n",
    "    \n",
    "        for j in x1:\n",
    "            new_list1.append(convert(j))\n",
    "    \n",
    "        return MultiPolygon((Polygon(new_list0), Polygon(new_list1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "####Create Directories with Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "YEARS = [\"2010\", \"2011\", \"2012\", \"2013\", \"2014\"]\n",
    "NAICS = list(df.groupby(['NAICS_LABEL', 'PNATITL', 'SICD']).agg('count').index.get_level_values(0))\n",
    "PNATITL = list(df.groupby(['NAICS_LABEL', 'PNATITL', 'SICD']).agg('count').index.get_level_values(1))\n",
    "SICD = list(df.groupby(['NAICS_LABEL', 'PNATITL', 'SICD']).agg('count').index.get_level_values(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnt = len(PNATITL)\n",
    "base_loc = '/gpfs1/cusp/kl1771/nycem/Ref_LMI/geojson'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for year in YEARS:\n",
    "    year_folder = str(year)\n",
    "    \n",
    "    if year_folder in os.listdir(base_loc):\n",
    "        print 'already created'\n",
    "    else:\n",
    "        add_year = base_loc + \"/\" + year_folder\n",
    "        os.mkdir(add_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df10_grouped #grouped_files[0]\n",
    "year = \"2010\" # YEARS[0] \n",
    "\n",
    "base_year_loc = base_loc + \"/\" + year\n",
    "year_dir = os.listdir(base_year_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def createGeoJSON(pnatitl_loc, string2):\n",
    "    \n",
    "    #pnatitl_loc = base_year_loc + \"/\" + string1\n",
    "    sicd_code = string2.replace(\"/\", \"-\") \n",
    "    \n",
    "    df_temp = df[df['SICD'] == string2]\n",
    "    \n",
    "    result = pd.merge(df_temp, boros[['BoroName', 'CT2010', 'NTAName', 'Shape_Area', 'geometry']], \\\n",
    "                  left_on = ['SHP_BOROUGH', 'SHP_CENSUS_TRACT'], right_on = ['BoroName', 'CT2010'])\n",
    "    \n",
    "    return result\n",
    "    #result.loc[:'geometry'] = result.apply(convertCoordinates, axis = 1)\n",
    "    \n",
    "    #return result\n",
    "        \n",
    "    #geojson_string = gp.GeoDataFrame(result).to_json()\n",
    "    \n",
    "    ###loc = pnatitl_loc + \"/\" + sicd_code + \".json\"\n",
    "    \n",
    "#     with open(loc, 'wb') as fp:\n",
    "#         json.dump(gp.GeoDataFrame(result).to_json(), fp)\n",
    "\n",
    "    ###with open(\"test.json\", 'wb') as fp:\n",
    "       ### json.dump(ast.literal_eval(geojson_string), fp)\n",
    "\n",
    "#gp.GeoDataFrame(result).to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = createGeoJSON('ALL OTHER TRAVELER ACCOMMODATION', 'RESORTS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df10_grouped[df10_grouped['PNATITL'] == 'DIRECT MAIL ADVERTISING']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRMSIC</th>\n",
       "      <th>SICD</th>\n",
       "      <th>PNACODE</th>\n",
       "      <th>PNATITL</th>\n",
       "      <th>Geo_COUNTY</th>\n",
       "      <th>SHP_BOROUGH</th>\n",
       "      <th>SHP_CENSUS_TRACT</th>\n",
       "      <th>lmi_ct</th>\n",
       "      <th>EMPSDT_SUM</th>\n",
       "      <th>EMPSDT_MED</th>\n",
       "      <th>SLSVDT_SUM</th>\n",
       "      <th>SLSVDT_MED</th>\n",
       "      <th>count_SUM</th>\n",
       "      <th>NAICS</th>\n",
       "      <th>NAICS_LABEL</th>\n",
       "      <th>BoroName</th>\n",
       "      <th>CT2010</th>\n",
       "      <th>NTAName</th>\n",
       "      <th>Shape_Area</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>701111</td>\n",
       "      <td>RESORTS</td>\n",
       "      <td>72119909</td>\n",
       "      <td>ALL OTHER TRAVELER ACCOMMODATION</td>\n",
       "      <td>047</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>046800</td>\n",
       "      <td>28214</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>535</td>\n",
       "      <td>535</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>ACCOMMODATION AND FOOD SERVICES</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>046800</td>\n",
       "      <td>Borough Park</td>\n",
       "      <td>3193544.08631</td>\n",
       "      <td>POLYGON ((989367.3388061523 166651.3480224609,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>701111</td>\n",
       "      <td>RESORTS</td>\n",
       "      <td>72119909</td>\n",
       "      <td>ALL OTHER TRAVELER ACCOMMODATION</td>\n",
       "      <td>047</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>050500</td>\n",
       "      <td>20221</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>535</td>\n",
       "      <td>535</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>ACCOMMODATION AND FOOD SERVICES</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>050500</td>\n",
       "      <td>East Williamsburg</td>\n",
       "      <td>1823285.67621</td>\n",
       "      <td>POLYGON ((1000095.328796387 196198.4761962891,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>701111</td>\n",
       "      <td>RESORTS</td>\n",
       "      <td>72119909</td>\n",
       "      <td>ALL OTHER TRAVELER ACCOMMODATION</td>\n",
       "      <td>061</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>001502</td>\n",
       "      <td>113646</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>535</td>\n",
       "      <td>535</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>ACCOMMODATION AND FOOD SERVICES</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>001502</td>\n",
       "      <td>Battery Park City-Lower Manhattan</td>\n",
       "      <td>2201257.31829</td>\n",
       "      <td>(POLYGON ((985529.7434082031 195268.299987793,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>701111</td>\n",
       "      <td>RESORTS</td>\n",
       "      <td>72119909</td>\n",
       "      <td>ALL OTHER TRAVELER ACCOMMODATION</td>\n",
       "      <td>061</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>001600</td>\n",
       "      <td>35021</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>535</td>\n",
       "      <td>535</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>ACCOMMODATION AND FOOD SERVICES</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>001600</td>\n",
       "      <td>Chinatown</td>\n",
       "      <td>2233319.75762</td>\n",
       "      <td>POLYGON ((987256.4573974609 200392.9885864258,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>701111</td>\n",
       "      <td>RESORTS</td>\n",
       "      <td>72119909</td>\n",
       "      <td>ALL OTHER TRAVELER ACCOMMODATION</td>\n",
       "      <td>061</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>004400</td>\n",
       "      <td>92173</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>535</td>\n",
       "      <td>535</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>ACCOMMODATION AND FOOD SERVICES</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>004400</td>\n",
       "      <td>Stuyvesant Town-Cooper Village</td>\n",
       "      <td>4277454.31258</td>\n",
       "      <td>(POLYGON ((994681.4056396484 203127.6748046875...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PRMSIC     SICD   PNACODE                           PNATITL Geo_COUNTY  \\\n",
       "0  701111  RESORTS  72119909  ALL OTHER TRAVELER ACCOMMODATION        047   \n",
       "1  701111  RESORTS  72119909  ALL OTHER TRAVELER ACCOMMODATION        047   \n",
       "2  701111  RESORTS  72119909  ALL OTHER TRAVELER ACCOMMODATION        061   \n",
       "3  701111  RESORTS  72119909  ALL OTHER TRAVELER ACCOMMODATION        061   \n",
       "4  701111  RESORTS  72119909  ALL OTHER TRAVELER ACCOMMODATION        061   \n",
       "\n",
       "  SHP_BOROUGH SHP_CENSUS_TRACT  lmi_ct  EMPSDT_SUM  EMPSDT_MED  SLSVDT_SUM  \\\n",
       "0    Brooklyn           046800   28214           5           5         535   \n",
       "1    Brooklyn           050500   20221           5           5         535   \n",
       "2   Manhattan           001502  113646           5           5         535   \n",
       "3   Manhattan           001600   35021           5           5         535   \n",
       "4   Manhattan           004400   92173           5           5         535   \n",
       "\n",
       "   SLSVDT_MED  count_SUM NAICS                      NAICS_LABEL   BoroName  \\\n",
       "0         535          1    72  ACCOMMODATION AND FOOD SERVICES   Brooklyn   \n",
       "1         535          1    72  ACCOMMODATION AND FOOD SERVICES   Brooklyn   \n",
       "2         535          1    72  ACCOMMODATION AND FOOD SERVICES  Manhattan   \n",
       "3         535          1    72  ACCOMMODATION AND FOOD SERVICES  Manhattan   \n",
       "4         535          1    72  ACCOMMODATION AND FOOD SERVICES  Manhattan   \n",
       "\n",
       "   CT2010                            NTAName     Shape_Area  \\\n",
       "0  046800                       Borough Park  3193544.08631   \n",
       "1  050500                  East Williamsburg  1823285.67621   \n",
       "2  001502  Battery Park City-Lower Manhattan  2201257.31829   \n",
       "3  001600                          Chinatown  2233319.75762   \n",
       "4  004400     Stuyvesant Town-Cooper Village  4277454.31258   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((989367.3388061523 166651.3480224609,...  \n",
       "1  POLYGON ((1000095.328796387 196198.4761962891,...  \n",
       "2  (POLYGON ((985529.7434082031 195268.299987793,...  \n",
       "3  POLYGON ((987256.4573974609 200392.9885864258,...  \n",
       "4  (POLYGON ((994681.4056396484 203127.6748046875...  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RESORTSTEST = df10_grouped[df10_grouped['SICD'] == 'RESORTS']\n",
    "\n",
    "result = pd.merge(RESORTSTEST, boros[['BoroName', 'CT2010', 'NTAName', 'Shape_Area', 'geometry']], \\\n",
    "                  left_on = ['SHP_BOROUGH', 'SHP_CENSUS_TRACT'], right_on = ['BoroName', 'CT2010'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result.loc[:,'geometry'] = result.apply(convertCoordinates, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "malformed string",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-e539d4f3f9f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mpnatitl_loc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnaics_loc\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpnatitl\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[1;31m#create file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m             \u001b[0mcreateGeoJSON\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpnatitl_loc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msicd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-46-8191174dd88e>\u001b[0m in \u001b[0;36mcreateGeoJSON\u001b[1;34m(pnatitl_loc, string2)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mast\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mliteral_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgeojson_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/opt/rh/anaconda/root/lib/python2.7/ast.pyc\u001b[0m in \u001b[0;36mliteral_eval\u001b[1;34m(node_or_string)\u001b[0m\n\u001b[0;32m     78\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mleft\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'malformed string'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_or_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/rh/anaconda/root/lib/python2.7/ast.pyc\u001b[0m in \u001b[0;36m_convert\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             return dict((_convert(k), _convert(v)) for k, v\n\u001b[1;32m---> 63\u001b[1;33m                         in zip(node.keys, node.values))\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mName\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_safe_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/rh/anaconda/root/lib/python2.7/ast.pyc\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m((k, v))\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_convert\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0melts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m             return dict((_convert(k), _convert(v)) for k, v\n\u001b[0m\u001b[0;32m     63\u001b[0m                         in zip(node.keys, node.values))\n\u001b[0;32m     64\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mName\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/rh/anaconda/root/lib/python2.7/ast.pyc\u001b[0m in \u001b[0;36m_convert\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_convert\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0melts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_convert\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0melts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             return dict((_convert(k), _convert(v)) for k, v\n",
      "\u001b[1;32m/opt/rh/anaconda/root/lib/python2.7/ast.pyc\u001b[0m in \u001b[0;36m_convert\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             return dict((_convert(k), _convert(v)) for k, v\n\u001b[1;32m---> 63\u001b[1;33m                         in zip(node.keys, node.values))\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mName\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_safe_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/rh/anaconda/root/lib/python2.7/ast.pyc\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m((k, v))\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_convert\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0melts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m             return dict((_convert(k), _convert(v)) for k, v\n\u001b[0m\u001b[0;32m     63\u001b[0m                         in zip(node.keys, node.values))\n\u001b[0;32m     64\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mName\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/rh/anaconda/root/lib/python2.7/ast.pyc\u001b[0m in \u001b[0;36m_convert\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             return dict((_convert(k), _convert(v)) for k, v\n\u001b[1;32m---> 63\u001b[1;33m                         in zip(node.keys, node.values))\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mName\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_safe_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/rh/anaconda/root/lib/python2.7/ast.pyc\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m((k, v))\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_convert\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0melts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m             return dict((_convert(k), _convert(v)) for k, v\n\u001b[0m\u001b[0;32m     63\u001b[0m                         in zip(node.keys, node.values))\n\u001b[0;32m     64\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mName\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/rh/anaconda/root/lib/python2.7/ast.pyc\u001b[0m in \u001b[0;36m_convert\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mleft\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'malformed string'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_or_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: malformed string"
     ]
    }
   ],
   "source": [
    "for index in range(cnt): \n",
    "    \n",
    "    year_dir = os.listdir(base_year_loc)\n",
    "    \n",
    "    naics = NAICS[index]\n",
    "    pnatitl = PNATITL[index].replace(\"/\", \"-\")\n",
    "    sicd = SICD[index]\n",
    "    \n",
    "    if naics not in os.listdir(base_year_loc): \n",
    "        naics_loc = base_year_loc + \"/\" + naics\n",
    "        os.mkdir(naics_loc)\n",
    "        \n",
    "        pnatitl_loc = naics_loc + \"/\" + pnatitl \n",
    "        os.mkdir(pnatitl_loc)\n",
    "        #create file \n",
    "        createGeoJSON(pnatitl_loc, sicd)\n",
    "        \n",
    "    else: \n",
    "        naics_loc = base_year_loc + \"/\" + naics\n",
    "        \n",
    "        if pnatitl not in os.listdir(naics_loc):\n",
    "            pnatitl_loc = naics_loc + \"/\" + pnatitl \n",
    "            os.mkdir(pnatitl_loc)\n",
    "            #create file \n",
    "            createGeoJSON(pnatitl_loc, sicd)\n",
    "            \n",
    "        else: \n",
    "            \n",
    "            pnatitl_loc = naics_loc + \"/\" + pnatitl \n",
    "            #create file \n",
    "            createGeoJSON(pnatitl_loc, sicd)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'base_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-8031691ee445>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0myear_folder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0myear_folder\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[1;34m'already created'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'base_dir' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "apm = base_year_loc + \"/\" + \"ABRASIVE PROD MANUFACTURING\"\n",
    "ac = base_year_loc + \"/\"  + \"AC REFRIGERATION & FORCED AIR HEATING\"\n",
    "\n",
    "os.mkdir(apm)\n",
    "os.mkdir(ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df10_grouped.groupby(['PNATITL', 'SICD']).agg('count').head(10)\n",
    "\n",
    "x = \"INTERNET PUBLISHING/BROADCASTING/WEB SEARCH PRTLS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'INTERNET PUBLISHING-BROADCASTING-WEB SEARCH PRTLS'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.replace(\"/\", \"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-73.92519212761768, 40.81801137088798]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert([1004958.0781860352, 237310.06280517578])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = df10_grouped[df10_grouped['PNATITL'] == 'DIRECT MAIL ADVERTISING']\n",
    "result1 = pd.merge(result, boros[['BoroName', 'CT2010', 'NTAName', 'Shape_Area', 'geometry']], \\\n",
    "                  left_on = ['SHP_BOROUGH', 'SHP_CENSUS_TRACT'], right_on = ['BoroName', 'CT2010'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#testdf = result1[result1[\"SHP_BOROUGH\"] == 'Manhattan'].ix[50:52,]\n",
    "testdf = result1\n",
    "# type(testdf['geometry'][0])\n",
    "#type(testdf['geometry'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x0 = list(testdf['geometry'][2][0].exterior.coords)\n",
    "x1 = list(testdf['geometry'][2][1].exterior.coords) \n",
    "\n",
    "new_list0 = []\n",
    "new_list1 = []\n",
    "\n",
    "for i in x0:\n",
    "    new_list0.append(convert(i))\n",
    "    \n",
    "for j in x1:\n",
    "    new_list1.append(convert(j))\n",
    "    \n",
    "x = MultiPolygon((Polygon(new_list0), Polygon(new_list1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result1.loc[:,('geometry')] = result1.apply(testfunction, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testdf = result1.ix[0:3,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('test.geojson', 'wb') as fp:\n",
    "    json.dump(ast.literal_eval(stringVersion), fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "stringVersion= gp.GeoDataFrame(testdf).to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ls' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-566-836d01611975>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# with open('/Users/krluna/Ref_LMI/test.geojson') as fp:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#     json.dump(ast.literal_eval(stringVersion), fp)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ls' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('/Users/krluna/Ref_LMI/test.geojson') as fp:\n",
    "    json.dump(ast.literal_eval(stringVersion), fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rm test.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import csv \n",
    "import StringIO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open(\"test.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = StringIO.StringIO(f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "reader = csv.reader(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<open file 'test.geojson', mode 'r' at 0x11edca030>\n"
     ]
    }
   ],
   "source": [
    "print x.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testjson = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testjson = testjson.replace(\" \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"test1.geojson\", 'wb') as fp:\n",
    "        json.dump(testjson, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# testjson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
