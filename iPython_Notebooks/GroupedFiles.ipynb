{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df10 = pd.read_csv(\"Ref10_LMI.csv\", index_col = 0, dtype = {'SHP_BOROUGH': object, 'SHP_CENSUS_TRACT': object, 'SHP_CENSUS_BLOCK': object, 'Geo_COUNTY': object} )\n",
    "df11 = pd.read_csv(\"Ref11_LMI.csv\", index_col = 0, dtype = {'SHP_BOROUGH': object, 'SHP_CENSUS_TRACT': object, 'SHP_CENSUS_BLOCK': object, 'Geo_COUNTY': object} )\n",
    "df12 = pd.read_csv(\"Ref12_LMI.csv\", index_col = 0, dtype = {'SHP_BOROUGH': object, 'SHP_CENSUS_TRACT': object, 'SHP_CENSUS_BLOCK': object, 'Geo_COUNTY': object} )\n",
    "df13 = pd.read_csv(\"Ref13_LMI.csv\", index_col = 0, dtype = {'SHP_BOROUGH': object, 'SHP_CENSUS_TRACT': object, 'SHP_CENSUS_BLOCK': object, 'Geo_COUNTY': object} )\n",
    "df14 = pd.read_csv(\"Ref14_LMI.csv\", index_col = 0, dtype = {'SHP_BOROUGH': object, 'SHP_CENSUS_TRACT': object, 'SHP_CENSUS_BLOCK': object, 'Geo_COUNTY': object} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = [df10, df11, df12, df13, df14]\n",
    "\n",
    "for df in files:\n",
    "    df['count'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df10_grouped = df10.groupby(['PRMSIC', 'PRMSICD', 'PNACODE', 'PNATITL', 'Geo_COUNTY', 'SHP_BOROUGH', 'SHP_CENSUS_TRACT', 'lmi_ct'])['EMPSDT', 'SLSVDT', 'count'].agg(['sum', 'median']).reset_index()\n",
    "df11_grouped = df11.groupby(['PRMSIC', 'SICD', 'PNACODE', 'PNATITL', 'Geo_COUNTY', 'SHP_BOROUGH', 'SHP_CENSUS_TRACT', 'lmi_ct'])['EMPSDT', 'SLSVDT', 'count'].agg(['sum', 'median']).reset_index()\n",
    "df12_grouped = df12.groupby(['PRMSIC', 'SICD', 'PNACODE', 'PNATITL', 'Geo_COUNTY', 'SHP_BOROUGH', 'SHP_CENSUS_TRACT', 'lmi_ct'])['EMPSDT', 'SLSVDT', 'count'].agg(['sum', 'median']).reset_index()\n",
    "df13_grouped = df13.groupby(['PRMSIC', 'SICD', 'PNACODE', 'PNATITL', 'Geo_COUNTY', 'SHP_BOROUGH', 'SHP_CENSUS_TRACT', 'lmi_ct'])['EMPSDT', 'SLSVDT', 'count'].agg(['sum', 'median']).reset_index()\n",
    "df14_grouped = df14.groupby(['PRMSIC', 'SICD', 'PNACODE', 'PNATITL', 'Geo_COUNTY', 'SHP_BOROUGH', 'SHP_CENSUS_TRACT', 'lmi_ct'])['EMPSDT', 'SLSVDT', 'count'].agg(['sum', 'median']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped_files = [df10_grouped, df11_grouped, df12_grouped, df13_grouped, df14_grouped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = ['PRMSIC', 'SICD', 'PNACODE', 'PNATITL', 'Geo_COUNTY', 'SHP_BOROUGH', 'SHP_CENSUS_TRACT', 'lmi_ct', \\\n",
    "        'EMPSDT_SUM', 'EMPSDT_MED', 'SLSVDT_SUM', 'SLSVDT_MED', 'count_SUM', 'count_MED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getNAICS(row):\n",
    "    code = str(row['PNACODE'])[0:2]\n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getNAICSLabel(row):\n",
    "    label = naicsCODES[row['NAICS']] \n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "naicsCODES = \\\n",
    "{'11': 'AGRICULTURE, FORESTRY, FISHING AND HUNTING',\n",
    " '21': 'MINING',\n",
    " '22': 'UTILITIES',\n",
    " '23': 'CONSTRUCTION',\n",
    " '31': 'MANUFACTURING',\n",
    " '32': 'MANUFACTURING',\n",
    " '33': 'MANUFACTURING',\n",
    " '42': 'WHOLESALE TRADE',\n",
    " '44': 'RETAIL TRADE',\n",
    " '45': 'RETAIL TRADE',\n",
    " '48': 'TRANSPORTATION AND WAREHOUSING',\n",
    " '49': 'TRANSPORTATION AND WAREHOUSING',\n",
    " '51': 'INFORMATION',\n",
    " '52': 'FINANCE AND INSURANCE',\n",
    " '53': 'REAL ESTATE RENTAL AND LEASING',\n",
    " '54': 'PROFESSIONAL, SCIENTIFIC, AND TECHNICAL SERVICES',\n",
    " '55': 'MANAGEMENT OF COMPANIES AND ENTERPRISES',\n",
    " '56': 'ADMINISTRATIVE AND SUPPORT AND WASTE MANAGEMENT AND REMEDIATION SERVICES',\n",
    " '61': 'EDUCATIONAL SERVICES',\n",
    " '62': 'HEALTH CARE AND SOCIAL ASSISTANCE',\n",
    " '71': 'ARTS, ENTERTAINMENT, AND RECREATION',\n",
    " '72': 'ACCOMMODATION AND FOOD SERVICES',\n",
    " '81': 'OTHER SERVICES (EXCEPT PUBLIC ADMINISTRATION)',\n",
    " '92': 'PUBLIC ADMINISTRATION',\n",
    " '99': 'UNCLASSIFIED'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for df in grouped_files:\n",
    "    df.columns = df.columns.droplevel(1)\n",
    "    df.columns = cols \n",
    "    del df['count_MED']\n",
    "    df.loc[:,'NAICS'] = df.apply(getNAICS, axis = 1)\n",
    "    df.loc[:,'NAICS_LABEL'] = df.apply(getNAICSLabel, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####don't use below code - no need to save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df10_grouped.to_csv(\"df10_grouped.csv\")\n",
    "df11_grouped.to_csv(\"df11_grouped.csv\")\n",
    "df12_grouped.to_csv(\"df12_grouped.csv\") \n",
    "df13_grouped.to_csv(\"df13_grouped.csv\")\n",
    "df14_grouped.to_csv(\"df14_grouped.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import geopandas as gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "boros = gp.GeoDataFrame.from_file(\"../nycem_shapfiles/nyct2010_15b/nyct2010.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####test drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df10_grouped[df10_grouped['SICD'] == 'BEAUTY SALONS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = pd.merge(df, boros[['BoroName', 'CT2010', 'NTAName', 'Shape_Area', 'geometry']], \\\n",
    "                  left_on = ['SHP_BOROUGH', 'SHP_CENSUS_TRACT'], right_on = ['BoroName', 'CT2010'])\n",
    "del result['BoroName']\n",
    "del result['CT2010']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Figure out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import shapefile\n",
    "from pyproj import Proj, transform \n",
    "from shapely.geometry import Polygon\n",
    "from shapely.geometry import MultiPolygon\n",
    "\n",
    "def convert(li):\n",
    "    f = 0.304800\n",
    "    inProj = Proj(init='epsg:2263')\n",
    "    outProj = Proj(init='epsg:4326')\n",
    "    x0,y0 = li[0]*f, li[1]*f\n",
    "    x2,y2 = transform(inProj,outProj,x0,y0)\n",
    "    \n",
    "    return (x2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sf = shapefile.Reader(\"../nycem_shapfiles/nyct2010_15b/nyct2010.shp\")\n",
    "shapes = sf.shapes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shapely.geometry.polygon.Polygon"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Polygon(convertPolygon(shapes[0].points)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.polygon.Polygon'>\n"
     ]
    }
   ],
   "source": [
    "print type(boros.ix[0]['geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ">>> p1 = Polygon([(0, 0), (1, 0), (1, 1)])\n",
    ">>> p2 = Polygon([(0, 0), (1, 0), (1, 1), (0, 1)])\n",
    ">>> p3 = Polygon([(2, 0), (3, 0), (3, 1), (2, 1)])\n",
    "\n",
    "g = gp.GeoSeries([p1, p2, p3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLYGON ((0 0, 1 0, 1 1, 0 0))\n"
     ]
    }
   ],
   "source": [
    "print g[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convertPolygon(list_of_points):\n",
    "    polygon_points = [] \n",
    "    for i in list_of_points:\n",
    "        new_point = tuple(convert(i))\n",
    "        polygon_points.append(new_point)\n",
    "    return polygon_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "boros.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array('d', [962269.1260375977, 962288.7224121094, 962548.4429931641, 962368.407409668, 962291.7900390625, 962144.5823974609, 961894.1400146484, 961637.3491821289, 961685.0524291992, 961742.125793457, 961516.8474121094, 961508.2352294922, 961479.7280273438, 961414.4558105469, 960650.7994384766, 960047.7131958008, 960079.5504150391, 960099.8128051758, 960153.1690063477, 960195.0620117188, 960237.9426269531, 960452.7714233398, 960669.7493896484, 960898.8204345703, 961473.7766113281, 961391.0897827148, 961970.9147949219, 962269.1260375977])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boros['geometry'][0].exterior.coords.xy[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "####Create Directories with Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = grouped_files[4]\n",
    "year = YEARS[4] \n",
    "\n",
    "base_year_loc = base_loc + \"/\" + year\n",
    "year_dir = os.listdir(base_year_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "YEARS = [\"2010\", \"2011\", \"2012\", \"2013\", \"2014\"]\n",
    "NAICS = list(df.groupby(['NAICS_LABEL', 'PNATITL', 'SICD']).agg('count').index.get_level_values(0))\n",
    "PNATITL = list(df.groupby(['NAICS_LABEL', 'PNATITL', 'SICD']).agg('count').index.get_level_values(1))\n",
    "SICD = list(df.groupby(['NAICS_LABEL', 'PNATITL', 'SICD']).agg('count').index.get_level_values(2))\n",
    "\n",
    "base_loc = \n",
    "cnt = len(PNATITL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def createGeoJSON(pnatitl_loc, string2):\n",
    "    \n",
    "    #pnatitl_loc = base_year_loc + \"/\" + string1\n",
    "    sicd_code = string2.replace(\"/\", \"-\") \n",
    "    \n",
    "    df_temp = df[df['SICD'] == string2]\n",
    "    \n",
    "    result = pd.merge(df_temp, boros[['BoroName', 'CT2010', 'NTAName', 'Shape_Area', 'geometry']], \\\n",
    "                  left_on = ['SHP_BOROUGH', 'SHP_CENSUS_TRACT'], right_on = ['BoroName', 'CT2010'])\n",
    "    \n",
    "    loc = pnatitl_loc + \"/\" + sicd_code + \".json\"\n",
    "    \n",
    "    with open(loc, 'wb') as fp:\n",
    "        json.dump(gp.GeoDataFrame(result).to_json(), fp)\n",
    "\n",
    "#gp.GeoDataFrame(result).to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for index in range(cnt): \n",
    "    \n",
    "    year_dir = os.listdir(base_year_loc)\n",
    "    \n",
    "    naics = NAICS[index]\n",
    "    pnatitl = PNATITL[index].replace(\"/\", \"-\")\n",
    "    sicd = SICD[index]\n",
    "    \n",
    "    if naics not in os.listdir(base_year_loc): \n",
    "        naics_loc = base_year_loc + \"/\" + naics\n",
    "        os.mkdir(naics_loc)\n",
    "        \n",
    "        pnatitl_loc = naics_loc + \"/\" + pnatitl \n",
    "        os.mkdir(pnatitl_loc)\n",
    "        #create file \n",
    "        createGeoJSON(pnatitl_loc, sicd)\n",
    "        \n",
    "    else: \n",
    "        naics_loc = base_year_loc + \"/\" + naics\n",
    "        \n",
    "        if pnatitl not in os.listdir(naics_loc):\n",
    "            pnatitl_loc = naics_loc + \"/\" + pnatitl \n",
    "            os.mkdir(pnatitl_loc)\n",
    "            #create file \n",
    "            createGeoJSON(pnatitl_loc, sicd)\n",
    "            \n",
    "        else: \n",
    "            \n",
    "            pnatitl_loc = naics_loc + \"/\" + pnatitl \n",
    "            #create file \n",
    "            createGeoJSON(pnatitl_loc, sicd)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'base_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-8031691ee445>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0myear_folder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0myear_folder\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[1;34m'already created'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'base_dir' is not defined"
     ]
    }
   ],
   "source": [
    "for year in YEARS:\n",
    "    year_folder = str(year)\n",
    "    \n",
    "    if year_folder in os.listdir(base_dir):\n",
    "        print 'already created'\n",
    "    else:\n",
    "        add_year = base_dir + \"/\" + year_folder\n",
    "        os.mkdir(add_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "apm = base_year_loc + \"/\" + \"ABRASIVE PROD MANUFACTURING\"\n",
    "ac = base_year_loc + \"/\"  + \"AC REFRIGERATION & FORCED AIR HEATING\"\n",
    "\n",
    "os.mkdir(apm)\n",
    "os.mkdir(ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df10_grouped.groupby(['PNATITL', 'SICD']).agg('count').head(10)\n",
    "\n",
    "x = \"INTERNET PUBLISHING/BROADCASTING/WEB SEARCH PRTLS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'INTERNET PUBLISHING-BROADCASTING-WEB SEARCH PRTLS'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.replace(\"/\", \"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-73.92519212761768, 40.81801137088798]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert([1004958.0781860352, 237310.06280517578])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = df10_grouped[df10_grouped['PNATITL'] == 'DIRECT MAIL ADVERTISING']\n",
    "result1 = pd.merge(result, boros[['BoroName', 'CT2010', 'NTAName', 'Shape_Area', 'geometry']], \\\n",
    "                  left_on = ['SHP_BOROUGH', 'SHP_CENSUS_TRACT'], right_on = ['BoroName', 'CT2010'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#testdf = result1[result1[\"SHP_BOROUGH\"] == 'Manhattan'].ix[50:52,]\n",
    "testdf = result1\n",
    "# type(testdf['geometry'][0])\n",
    "#type(testdf['geometry'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x0 = list(testdf['geometry'][2][0].exterior.coords)\n",
    "x1 = list(testdf['geometry'][2][1].exterior.coords) \n",
    "\n",
    "new_list0 = []\n",
    "new_list1 = []\n",
    "\n",
    "for i in x0:\n",
    "    new_list0.append(convert(i))\n",
    "    \n",
    "for j in x1:\n",
    "    new_list1.append(convert(j))\n",
    "    \n",
    "x = MultiPolygon((Polygon(new_list0), Polygon(new_list1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def testfunction(row):\n",
    "    geo = row['geometry']\n",
    "    \n",
    "    try: \n",
    "        x = list(geo.exterior.coords)\n",
    "        new_list = [] \n",
    "    \n",
    "        for i in x:\n",
    "            new_list.append(convert(i))\n",
    "        \n",
    "        return Polygon(new_list)\n",
    "    \n",
    "    except: \n",
    "        x0 = list(testdf['geometry'][2][0].exterior.coords)\n",
    "        x1 = list(testdf['geometry'][2][1].exterior.coords) \n",
    "\n",
    "        new_list0 = []\n",
    "        new_list1 = []\n",
    "\n",
    "        for i in x0:\n",
    "            new_list0.append(convert(i))\n",
    "    \n",
    "        for j in x1:\n",
    "            new_list1.append(convert(j))\n",
    "    \n",
    "        return MultiPolygon((Polygon(new_list0), Polygon(new_list1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result1.loc[:,('geometry')] = result1.apply(testfunction, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testdf = result1.ix[0:3,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('test.geojson', 'wb') as fp:\n",
    "    json.dump(ast.literal_eval(stringVersion), fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "stringVersion= gp.GeoDataFrame(testdf).to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ls' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-566-836d01611975>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# with open('/Users/krluna/Ref_LMI/test.geojson') as fp:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#     json.dump(ast.literal_eval(stringVersion), fp)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ls' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# with open('/Users/krluna/Ref_LMI/test.geojson') as fp:\n",
    "#     json.dump(ast.literal_eval(stringVersion), fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rm test.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import csv \n",
    "import StringIO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open(\"test.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = StringIO.StringIO(f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "reader = csv.reader(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<open file 'test.geojson', mode 'r' at 0x11edca030>\n"
     ]
    }
   ],
   "source": [
    "print x.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testjson = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testjson = testjson.replace(\" \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"test1.geojson\", 'wb') as fp:\n",
    "        json.dump(testjson, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# testjson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
