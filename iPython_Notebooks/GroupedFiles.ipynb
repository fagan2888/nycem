{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df10 = pd.read_csv(\"Ref10_LMI.csv\", index_col = 0, dtype = {'SHP_BOROUGH': object, 'SHP_CENSUS_TRACT': object, 'SHP_CENSUS_BLOCK': object, 'Geo_COUNTY': object} )\n",
    "df11 = pd.read_csv(\"Ref11_LMI.csv\", index_col = 0, dtype = {'SHP_BOROUGH': object, 'SHP_CENSUS_TRACT': object, 'SHP_CENSUS_BLOCK': object, 'Geo_COUNTY': object} )\n",
    "df12 = pd.read_csv(\"Ref12_LMI.csv\", index_col = 0, dtype = {'SHP_BOROUGH': object, 'SHP_CENSUS_TRACT': object, 'SHP_CENSUS_BLOCK': object, 'Geo_COUNTY': object} )\n",
    "df13 = pd.read_csv(\"Ref13_LMI.csv\", index_col = 0, dtype = {'SHP_BOROUGH': object, 'SHP_CENSUS_TRACT': object, 'SHP_CENSUS_BLOCK': object, 'Geo_COUNTY': object} )\n",
    "df14 = pd.read_csv(\"Ref14_LMI.csv\", index_col = 0, dtype = {'SHP_BOROUGH': object, 'SHP_CENSUS_TRACT': object, 'SHP_CENSUS_BLOCK': object, 'Geo_COUNTY': object} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = [df10, df11, df12, df13, df14]\n",
    "\n",
    "for df in files:\n",
    "    df['count'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df10_grouped = df10.groupby(['PRMSIC', 'PRMSICD', 'PNACODE', 'PNATITL', 'Geo_COUNTY', 'SHP_BOROUGH', 'SHP_CENSUS_TRACT', 'lmi_ct'])['EMPSDT', 'SLSVDT', 'count'].agg(['sum', 'median']).reset_index()\n",
    "df11_grouped = df11.groupby(['PRMSIC', 'SICD', 'PNACODE', 'PNATITL', 'Geo_COUNTY', 'SHP_BOROUGH', 'SHP_CENSUS_TRACT', 'lmi_ct'])['EMPSDT', 'SLSVDT', 'count'].agg(['sum', 'median']).reset_index()\n",
    "df12_grouped = df12.groupby(['PRMSIC', 'SICD', 'PNACODE', 'PNATITL', 'Geo_COUNTY', 'SHP_BOROUGH', 'SHP_CENSUS_TRACT', 'lmi_ct'])['EMPSDT', 'SLSVDT', 'count'].agg(['sum', 'median']).reset_index()\n",
    "df13_grouped = df13.groupby(['PRMSIC', 'SICD', 'PNACODE', 'PNATITL', 'Geo_COUNTY', 'SHP_BOROUGH', 'SHP_CENSUS_TRACT', 'lmi_ct'])['EMPSDT', 'SLSVDT', 'count'].agg(['sum', 'median']).reset_index()\n",
    "df14_grouped = df14.groupby(['PRMSIC', 'SICD', 'PNACODE', 'PNATITL', 'Geo_COUNTY', 'SHP_BOROUGH', 'SHP_CENSUS_TRACT', 'lmi_ct'])['EMPSDT', 'SLSVDT', 'count'].agg(['sum', 'median']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped_files = [df10_grouped, df11_grouped, df12_grouped, df13_grouped, df14_grouped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = ['PRMSIC', 'SICD', 'PNACODE', 'PNATITL', 'Geo_COUNTY', 'SHP_BOROUGH', 'SHP_CENSUS_TRACT', 'lmi_ct', \\\n",
    "        'EMPSDT_SUM', 'EMPSDT_MED', 'SLSVDT_SUM', 'SLSVDT_MED', 'count_SUM', 'count_MED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getNAICS(row):\n",
    "    code = str(row['PNACODE'])[0:2]\n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getNAICSLabel(row):\n",
    "    label = naicsCODES[row['NAICS']] \n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "naicsCODES = \\\n",
    "{'11': 'AGRICULTURE, FORESTRY, FISHING AND HUNTING',\n",
    " '21': 'MINING',\n",
    " '22': 'UTILITIES',\n",
    " '23': 'CONSTRUCTION',\n",
    " '31': 'MANUFACTURING',\n",
    " '32': 'MANUFACTURING',\n",
    " '33': 'MANUFACTURING',\n",
    " '42': 'WHOLESALE TRADE',\n",
    " '44': 'RETAIL TRADE',\n",
    " '45': 'RETAIL TRADE',\n",
    " '48': 'TRANSPORTATION AND WAREHOUSING',\n",
    " '49': 'TRANSPORTATION AND WAREHOUSING',\n",
    " '51': 'INFORMATION',\n",
    " '52': 'FINANCE AND INSURANCE',\n",
    " '53': 'REAL ESTATE RENTAL AND LEASING',\n",
    " '54': 'PROFESSIONAL, SCIENTIFIC, AND TECHNICAL SERVICES',\n",
    " '55': 'MANAGEMENT OF COMPANIES AND ENTERPRISES',\n",
    " '56': 'ADMINISTRATIVE AND SUPPORT AND WASTE MANAGEMENT AND REMEDIATION SERVICES',\n",
    " '61': 'EDUCATIONAL SERVICES',\n",
    " '62': 'HEALTH CARE AND SOCIAL ASSISTANCE',\n",
    " '71': 'ARTS, ENTERTAINMENT, AND RECREATION',\n",
    " '72': 'ACCOMMODATION AND FOOD SERVICES',\n",
    " '81': 'OTHER SERVICES (EXCEPT PUBLIC ADMINISTRATION)',\n",
    " '92': 'PUBLIC ADMINISTRATION',\n",
    " '99': 'UNCLASSIFIED'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for df in grouped_files:\n",
    "    df.columns = df.columns.droplevel(1)\n",
    "    df.columns = cols \n",
    "    del df['count_MED']\n",
    "    df.loc[:,'NAICS'] = df.apply(getNAICS, axis = 1)\n",
    "    df.loc[:,'NAICS_LABEL'] = df.apply(getNAICSLabel, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####don't use below code - no need to save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df10_grouped.to_csv(\"df10_grouped.csv\")\n",
    "# df11_grouped.to_csv(\"df11_grouped.csv\")\n",
    "# df12_grouped.to_csv(\"df12_grouped.csv\") \n",
    "# df13_grouped.to_csv(\"df13_grouped.csv\")\n",
    "# df14_grouped.to_csv(\"df14_grouped.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "boros = gp.GeoDataFrame.from_file(\"../nyct2010_15b/nyct2010.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####test drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df10_grouped[df10_grouped['SICD'] == 'BEAUTY SALONS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = pd.merge(df, boros[['BoroName', 'CT2010', 'NTAName', 'Shape_Area', 'geometry']], \\\n",
    "                  left_on = ['SHP_BOROUGH', 'SHP_CENSUS_TRACT'], right_on = ['BoroName', 'CT2010'])\n",
    "del result['BoroName']\n",
    "del result['CT2010']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Figure out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import shapefile\n",
    "from pyproj import Proj, transform \n",
    "from shapely.geometry import Polygon\n",
    "from shapely.geometry import MultiPolygon\n",
    "\n",
    "def convert(li):\n",
    "    f = 0.304800\n",
    "    inProj = Proj(init='epsg:2263')\n",
    "    outProj = Proj(init='epsg:4326')\n",
    "    x0,y0 = li[0]*f, li[1]*f\n",
    "    x2,y2 = transform(inProj,outProj,x0,y0)\n",
    "    \n",
    "    return (x2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def convertPolygon(list_of_points):\n",
    "#     polygon_points = [] \n",
    "#     for i in list_of_points:\n",
    "#         new_point = tuple(convert(i))\n",
    "#         polygon_points.append(new_point)\n",
    "#     return polygon_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# boros['geometry'][0].exterior.coords.xy[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convertCoordinates(row):\n",
    "    geo = row['geometry']\n",
    "    \n",
    "    try: \n",
    "        x = list(geo.exterior.coords)\n",
    "        new_list = [] \n",
    "    \n",
    "        for i in x:\n",
    "            new_list.append(convert(i))\n",
    "        \n",
    "        return Polygon(new_list)\n",
    "    \n",
    "    except: \n",
    "        x0 = list(geo[0].exterior.coords)\n",
    "        x1 = list(geo[1].exterior.coords) \n",
    "\n",
    "        new_list0 = []\n",
    "        new_list1 = []\n",
    "\n",
    "        for i in x0:\n",
    "            new_list0.append(convert(i))\n",
    "    \n",
    "        for j in x1:\n",
    "            new_list1.append(convert(j))\n",
    "    \n",
    "        return MultiPolygon((Polygon(new_list0), Polygon(new_list1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "####Create Directories with Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "YEARS = [\"2010\", \"2011\", \"2012\", \"2013\", \"2014\"]\n",
    "NAICS = list(df.groupby(['NAICS_LABEL', 'PNATITL', 'SICD']).agg('count').index.get_level_values(0))\n",
    "PNATITL = list(df.groupby(['NAICS_LABEL', 'PNATITL', 'SICD']).agg('count').index.get_level_values(1))\n",
    "SICD = list(df.groupby(['NAICS_LABEL', 'PNATITL', 'SICD']).agg('count').index.get_level_values(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnt = len(PNATITL)\n",
    "base_loc = '/gpfs1/cusp/kl1771/nycem/Ref_LMI/geojson'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already created\n",
      "already created\n",
      "already created\n",
      "already created\n",
      "already created\n"
     ]
    }
   ],
   "source": [
    "for year in YEARS:\n",
    "    year_folder = str(year)\n",
    "    \n",
    "    if year_folder in os.listdir(base_loc):\n",
    "        print 'already created'\n",
    "    else:\n",
    "        add_year = base_loc + \"/\" + year_folder\n",
    "        os.mkdir(add_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df13_grouped #grouped_files[0]\n",
    "year = \"2013\" # YEARS[0] \n",
    "\n",
    "base_year_loc = base_loc + \"/\" + year\n",
    "year_dir = os.listdir(base_year_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def createGeoJSON(pnatitl_loc, string2):\n",
    "    \n",
    "    #pnatitl_loc = base_year_loc + \"/\" + string1\n",
    "    sicd_code = string2.replace(\"/\", \"-\") \n",
    "    \n",
    "    df_temp = df[df['SICD'] == string2]\n",
    "    \n",
    "    result = pd.merge(df_temp, boros[['BoroName', 'CT2010', 'NTAName', 'Shape_Area', 'geometry']], \\\n",
    "                  left_on = ['SHP_BOROUGH', 'SHP_CENSUS_TRACT'], right_on = ['BoroName', 'CT2010'])\n",
    "        \n",
    "    result = result[['PRMSIC', 'SICD', 'PNACODE', 'PNATITL', 'NAICS_LABEL', 'SHP_BOROUGH', 'SHP_CENSUS_TRACT', 'lmi_ct', \\\n",
    "                 'EMPSDT_SUM', 'EMPSDT_MED', 'SLSVDT_SUM', 'SLSVDT_MED', 'count_SUM', 'NTAName', 'Shape_Area', 'geometry']]\n",
    "    \n",
    "    result.columns = ['PRMSIC', 'SICD', 'PNACODE', 'PNATITL', 'NAICS', 'Borough', 'Census_Tract', \\\n",
    "                  'Median_Income_ct', 'EMPSDT_Sum', 'EMPSDT_Median', 'SLSVDT_Sum', 'SLSVDT_Median', \\\n",
    "                  'Business_Count', 'Neighborhood_Name', 'Shape_Area', 'geometry']\n",
    "    \n",
    "    result.loc[:,'geometry'] = result.apply(convertCoordinates, axis = 1)\n",
    "    geojson_string = gp.GeoDataFrame(result).to_json()\n",
    "    geojson_dict = json.loads(geojson_string)\n",
    "\n",
    "    loc = pnatitl_loc + \"/\" + sicd_code + \".geojson\"\n",
    "    \n",
    "    with open(loc, 'wb') as fp:\n",
    "        json.dump(geojson_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "healthSPA = df10_grouped[df10_grouped['SICD'] == 'HEALTH SPAS']\n",
    "\n",
    "result = pd.merge(healthSPA, boros[['BoroName', 'CT2010', 'NTAName', 'Shape_Area', 'geometry']], \\\n",
    "                   left_on = ['SHP_BOROUGH', 'SHP_CENSUS_TRACT'], right_on = ['BoroName', 'CT2010'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = result[['PRMSIC', 'SICD', 'PNACODE', 'PNATITL', 'NAICS_LABEL', 'SHP_BOROUGH', 'SHP_CENSUS_TRACT', 'lmi_ct', \\\n",
    "                 'EMPSDT_SUM', 'EMPSDT_MED', 'SLSVDT_SUM', 'SLSVDT_MED', 'count_SUM', 'NTAName', 'Shape_Area', 'geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result.columns = ['PRMSIC', 'SICD', 'PNACODE', 'PNATITL', 'NAICS', 'Borough', 'Census_Tract', \\\n",
    "                  'Median_Income_ct', 'EMPSDT_Sum', 'EMPSDT_Median', 'SLSVDT_Sum', 'SLSVDT_Median', \\\n",
    "                  'Business_Count', 'Neighborhood_Name', 'Shape_Area', 'geometry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "startTime = datetime.now()\n",
    "\n",
    "for index in range(cnt): \n",
    "    \n",
    "    year_dir = os.listdir(base_year_loc)\n",
    "    \n",
    "    naics = NAICS[index]\n",
    "    pnatitl = PNATITL[index].replace(\"/\", \"-\")\n",
    "    sicd = SICD[index]\n",
    "    \n",
    "    if naics not in os.listdir(base_year_loc): \n",
    "        naics_loc = base_year_loc + \"/\" + naics\n",
    "        os.mkdir(naics_loc)\n",
    "        \n",
    "        pnatitl_loc = naics_loc + \"/\" + pnatitl \n",
    "        os.mkdir(pnatitl_loc)\n",
    "        createGeoJSON(pnatitl_loc, sicd) \n",
    "\n",
    "        \n",
    "    else: \n",
    "        naics_loc = base_year_loc + \"/\" + naics\n",
    "        \n",
    "        if pnatitl not in os.listdir(naics_loc):\n",
    "            pnatitl_loc = naics_loc + \"/\" + pnatitl \n",
    "            os.mkdir(pnatitl_loc)\n",
    "            createGeoJSON(pnatitl_loc, sicd) \n",
    "          \n",
    "        else: \n",
    "            pnatitl_loc = naics_loc + \"/\" + pnatitl \n",
    "            createGeoJSON(pnatitl_loc, sicd) \n",
    "            \n",
    "print datetime.now() - startTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
