{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df10 = pd.read_csv(\"Ref10_LMI.csv\", index_col = 0, dtype = {'SHP_BOROUGH': object, 'SHP_CENSUS_TRACT': object, 'SHP_CENSUS_BLOCK': object, 'Geo_COUNTY': object} )\n",
    "df11 = pd.read_csv(\"Ref11_LMI.csv\", index_col = 0, dtype = {'SHP_BOROUGH': object, 'SHP_CENSUS_TRACT': object, 'SHP_CENSUS_BLOCK': object, 'Geo_COUNTY': object} )\n",
    "df12 = pd.read_csv(\"Ref12_LMI.csv\", index_col = 0, dtype = {'SHP_BOROUGH': object, 'SHP_CENSUS_TRACT': object, 'SHP_CENSUS_BLOCK': object, 'Geo_COUNTY': object} )\n",
    "df13 = pd.read_csv(\"Ref13_LMI.csv\", index_col = 0, dtype = {'SHP_BOROUGH': object, 'SHP_CENSUS_TRACT': object, 'SHP_CENSUS_BLOCK': object, 'Geo_COUNTY': object} )\n",
    "df14 = pd.read_csv(\"Ref14_LMI.csv\", index_col = 0, dtype = {'SHP_BOROUGH': object, 'SHP_CENSUS_TRACT': object, 'SHP_CENSUS_BLOCK': object, 'Geo_COUNTY': object} )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Filter by 100 Employees for PNATITL Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df10 = df10[(df10[\"EMPSDT\"] > 0) & (df10[\"EMPSDT\"] < 100)]\n",
    "df11 = df11[(df11[\"EMPSDT\"] > 0) & (df11[\"EMPSDT\"] < 100)]\n",
    "df12 = df12[(df12[\"EMPSDT\"] > 0) & (df12[\"EMPSDT\"] < 100)]\n",
    "df13 = df13[(df13[\"EMPSDT\"] > 0) & (df13[\"EMPSDT\"] < 100)]\n",
    "df14 = df14[(df14[\"EMPSDT\"] > 0) & (df14[\"EMPSDT\"] < 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = [df10, df11, df12, df13, df14]\n",
    "\n",
    "for df in files:\n",
    "    df['count'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Group by SICD Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df10_grouped = df10.groupby(['PRMSIC', 'PRMSICD', 'PNACODE', 'PNATITL', 'Geo_COUNTY', 'SHP_BOROUGH', 'SHP_CENSUS_TRACT', 'lmi_ct'])['EMPSDT', 'SLSVDT', 'count'].agg(['sum', 'median']).reset_index()\n",
    "df11_grouped = df11.groupby(['PRMSIC', 'SICD', 'PNACODE', 'PNATITL', 'Geo_COUNTY', 'SHP_BOROUGH', 'SHP_CENSUS_TRACT', 'lmi_ct'])['EMPSDT', 'SLSVDT', 'count'].agg(['sum', 'median']).reset_index()\n",
    "df12_grouped = df12.groupby(['PRMSIC', 'SICD', 'PNACODE', 'PNATITL', 'Geo_COUNTY', 'SHP_BOROUGH', 'SHP_CENSUS_TRACT', 'lmi_ct'])['EMPSDT', 'SLSVDT', 'count'].agg(['sum', 'median']).reset_index()\n",
    "df13_grouped = df13.groupby(['PRMSIC', 'SICD', 'PNACODE', 'PNATITL', 'Geo_COUNTY', 'SHP_BOROUGH', 'SHP_CENSUS_TRACT', 'lmi_ct'])['EMPSDT', 'SLSVDT', 'count'].agg(['sum', 'median']).reset_index()\n",
    "df14_grouped = df14.groupby(['PRMSIC', 'SICD', 'PNACODE', 'PNATITL', 'Geo_COUNTY', 'SHP_BOROUGH', 'SHP_CENSUS_TRACT', 'lmi_ct'])['EMPSDT', 'SLSVDT', 'count'].agg(['sum', 'median']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['PRMSIC', 'SICD', 'PNACODE', 'PNATITL', 'Geo_COUNTY', 'SHP_BOROUGH', 'SHP_CENSUS_TRACT', 'lmi_ct', \\\n",
    "        'EMPSDT_SUM', 'EMPSDT_MED', 'SLSVDT_SUM', 'SLSVDT_MED', 'count_SUM', 'count_MED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Group by PNATITL Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df10_grouped = df10.groupby(['PNACODE', 'PNATITL', 'Geo_COUNTY', 'SHP_BOROUGH', 'SHP_CENSUS_TRACT', 'lmi_ct'])['EMPSDT', 'SLSVDT', 'count'].agg(['sum', 'median']).reset_index()\n",
    "df11_grouped = df11.groupby(['PNACODE', 'PNATITL', 'Geo_COUNTY', 'SHP_BOROUGH', 'SHP_CENSUS_TRACT', 'lmi_ct'])['EMPSDT', 'SLSVDT', 'count'].agg(['sum', 'median']).reset_index()\n",
    "df12_grouped = df12.groupby(['PNACODE', 'PNATITL', 'Geo_COUNTY', 'SHP_BOROUGH', 'SHP_CENSUS_TRACT', 'lmi_ct'])['EMPSDT', 'SLSVDT', 'count'].agg(['sum', 'median']).reset_index()\n",
    "df13_grouped = df13.groupby(['PNACODE', 'PNATITL', 'Geo_COUNTY', 'SHP_BOROUGH', 'SHP_CENSUS_TRACT', 'lmi_ct'])['EMPSDT', 'SLSVDT', 'count'].agg(['sum', 'median']).reset_index()\n",
    "df14_grouped = df14.groupby(['PNACODE', 'PNATITL', 'Geo_COUNTY', 'SHP_BOROUGH', 'SHP_CENSUS_TRACT', 'lmi_ct'])['EMPSDT', 'SLSVDT', 'count'].agg(['sum', 'median']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['PNACODE', 'PNATITL', 'Geo_COUNTY', 'SHP_BOROUGH', 'SHP_CENSUS_TRACT', 'lmi_ct', \\\n",
    "        'EMPSDT_SUM', 'EMPSDT_MED', 'SLSVDT_SUM', 'SLSVDT_MED', 'count_SUM', 'count_MED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Append NAICS Labels (For Both SICD and PNATITL Groupings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped_files = [df10_grouped, df11_grouped, df12_grouped, df13_grouped, df14_grouped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getNAICS(row):\n",
    "    code = str(row['PNACODE'])[0:2]\n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getNAICSLabel(row):\n",
    "    label = naicsCODES[row['NAICS']] \n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createBoroCTCode(row):\n",
    "    new_county_code = counties_dict[row['Geo_COUNTY']]\n",
    "    grouping_code = new_county_code + row['SHP_CENSUS_TRACT']\n",
    "    return grouping_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "naicsCODES = \\\n",
    "{'11': 'AGRICULTURE, FORESTRY, FISHING AND HUNTING',\n",
    " '21': 'MINING',\n",
    " '22': 'UTILITIES',\n",
    " '23': 'CONSTRUCTION',\n",
    " '31': 'MANUFACTURING',\n",
    " '32': 'MANUFACTURING',\n",
    " '33': 'MANUFACTURING',\n",
    " '42': 'WHOLESALE TRADE',\n",
    " '44': 'RETAIL TRADE',\n",
    " '45': 'RETAIL TRADE',\n",
    " '48': 'TRANSPORTATION AND WAREHOUSING',\n",
    " '49': 'TRANSPORTATION AND WAREHOUSING',\n",
    " '51': 'INFORMATION',\n",
    " '52': 'FINANCE AND INSURANCE',\n",
    " '53': 'REAL ESTATE RENTAL AND LEASING',\n",
    " '54': 'PROFESSIONAL, SCIENTIFIC, AND TECHNICAL SERVICES',\n",
    " '55': 'MANAGEMENT OF COMPANIES AND ENTERPRISES',\n",
    " '56': 'ADMINISTRATIVE AND SUPPORT AND WASTE MANAGEMENT AND REMEDIATION SERVICES',\n",
    " '61': 'EDUCATIONAL SERVICES',\n",
    " '62': 'HEALTH CARE AND SOCIAL ASSISTANCE',\n",
    " '71': 'ARTS, ENTERTAINMENT, AND RECREATION',\n",
    " '72': 'ACCOMMODATION AND FOOD SERVICES',\n",
    " '81': 'OTHER SERVICES (EXCEPT PUBLIC ADMINISTRATION)',\n",
    " '92': 'PUBLIC ADMINISTRATION',\n",
    " '99': 'UNCLASSIFIED'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counties_dict = {\n",
    "    '085': '5',\n",
    "    '005': '2',\n",
    "    '047': '3',\n",
    "    '061': '1',\n",
    "    '081': '4'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_clusters = pd.read_csv(\"../Lodes/CTclusters_code.csv\", index_col = False, dtype = {'code': object})\n",
    "del df_clusters['Unnamed: 0']\n",
    "# ls ../Lodes/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for df in grouped_files:\n",
    "    df.columns = df.columns.droplevel(1)\n",
    "    df.columns = cols \n",
    "    del df['count_MED']\n",
    "    df.loc[:,'NAICS'] = df.apply(getNAICS, axis = 1)\n",
    "    df.loc[:,'NAICS_LABEL'] = df.apply(getNAICSLabel, axis = 1)\n",
    "    df.loc[:,'Grouping_Code'] = df.apply(createBoroCTCode, axis = 1)\n",
    "    #df = pd.merge(df, df_clusters[['cluster', 'code']], left_on = ['Grouping_Code'], right_on = ['code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df10_grouped = pd.merge(df10_grouped, df_clusters[['cluster', 'code']], left_on = ['Grouping_Code'], right_on = ['code'])\n",
    "df11_grouped = pd.merge(df11_grouped, df_clusters[['cluster', 'code']], left_on = ['Grouping_Code'], right_on = ['code'])\n",
    "df12_grouped = pd.merge(df12_grouped, df_clusters[['cluster', 'code']], left_on = ['Grouping_Code'], right_on = ['code'])\n",
    "df13_grouped = pd.merge(df13_grouped, df_clusters[['cluster', 'code']], left_on = ['Grouping_Code'], right_on = ['code'])\n",
    "df14_grouped = pd.merge(df14_grouped, df_clusters[['cluster', 'code']], left_on = ['Grouping_Code'], right_on = ['code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'PRMSIC', u'SICD', u'PNACODE', u'PNATITL', u'Geo_COUNTY',\n",
       "       u'SHP_BOROUGH', u'SHP_CENSUS_TRACT', u'lmi_ct', u'EMPSDT_SUM',\n",
       "       u'EMPSDT_MED', u'SLSVDT_SUM', u'SLSVDT_MED', u'count_SUM', u'NAICS',\n",
       "       u'NAICS_LABEL', u'Grouping_Code', u'cluster', u'code'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df10_grouped.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Upload Borough Shapefile Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "boros = gp.GeoDataFrame.from_file(\"../nyct2010_15b/nyct2010.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Append Shapefile Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import shapefile\n",
    "from pyproj import Proj, transform \n",
    "from shapely.geometry import Polygon\n",
    "from shapely.geometry import MultiPolygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert(li):\n",
    "    f = 0.304800\n",
    "    inProj = Proj(init='epsg:2263')\n",
    "    outProj = Proj(init='epsg:4326')\n",
    "    x0,y0 = li[0]*f, li[1]*f\n",
    "    x2,y2 = transform(inProj,outProj,x0,y0)\n",
    "    \n",
    "    return (x2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convertCoordinates(row):\n",
    "    geo = row['geometry']\n",
    "    \n",
    "    try: \n",
    "        x = list(geo.exterior.coords)\n",
    "        new_list = [] \n",
    "    \n",
    "        for i in x:\n",
    "            new_list.append(convert(i))\n",
    "        \n",
    "        return Polygon(new_list)\n",
    "    \n",
    "    except: \n",
    "        x0 = list(geo[0].exterior.coords)\n",
    "        x1 = list(geo[1].exterior.coords) \n",
    "\n",
    "        new_list0 = []\n",
    "        new_list1 = []\n",
    "\n",
    "        for i in x0:\n",
    "            new_list0.append(convert(i))\n",
    "    \n",
    "        for j in x1:\n",
    "            new_list1.append(convert(j))\n",
    "    \n",
    "        return MultiPolygon((Polygon(new_list0), Polygon(new_list1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "####Create Directories with Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#YEARS = [\"2010\", \"2011\", \"2012\", \"2013\", \"2014\"]\n",
    "#NAICS = list(df.groupby(['NAICS_LABEL', 'PNATITL']).agg('count').index.get_level_values(0))\n",
    "#PNATITL = list(df.groupby(['NAICS_LABEL', 'PNATITL']).agg('count').index.get_level_values(1))\n",
    "\n",
    "YEARS = [\"2010\", \"2011\", \"2012\", \"2013\", \"2014\"]\n",
    "NAICS = list(df.groupby(['NAICS_LABEL', 'PNATITL', 'SICD']).agg('count').index.get_level_values(0))\n",
    "PNATITL = list(df.groupby(['NAICS_LABEL', 'PNATITL', 'SICD']).agg('count').index.get_level_values(1))\n",
    "SICD = list(df.groupby(['NAICS_LABEL', 'PNATITL', 'SICD']).agg('count').index.get_level_values(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cnt = len(PNATITL)\n",
    "base_loc = '/gpfs1/cusp/kl1771/nycem/Ref_LMI/geojson'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already created\n",
      "already created\n",
      "already created\n",
      "already created\n",
      "already created\n"
     ]
    }
   ],
   "source": [
    "for year in YEARS:\n",
    "    year_folder = str(year)\n",
    "    \n",
    "    if year_folder in os.listdir(base_loc):\n",
    "        print 'already created'\n",
    "    else:\n",
    "        add_year = base_loc + \"/\" + year_folder\n",
    "        os.mkdir(add_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHANGE this Sam! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df14_grouped #change this df11_grouped, df12_grouped etc. \n",
    "year = \"2014\" # change this to 2011, 2012, 2013 etc, \n",
    "\n",
    "base_year_loc = base_loc + \"/\" + year\n",
    "year_dir = os.listdir(base_year_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def createGeoJSON(pnatitl_loc, string2):\n",
    "    \n",
    "    #pnatitl_loc = base_year_loc + \"/\" + string1\n",
    "    sicd_code = string2.replace(\"/\", \"-\")\n",
    "    sicd_file_name = sicd_code.replace(\"_\", \"\").replace(\", \", \"_\").replace(\" \", \"_\").replace(\"(\", \"\").\\\n",
    "    replace(\")\", \"\").lower()\n",
    "    \n",
    "\n",
    "    df_temp = df[df['SICD'] == string2]\n",
    "    \n",
    "    result = pd.merge(df_temp, boros[['BoroName', 'CT2010', 'NTAName', 'Shape_Area', 'geometry']], \\\n",
    "                  left_on = ['SHP_BOROUGH', 'SHP_CENSUS_TRACT'], right_on = ['BoroName', 'CT2010'])\n",
    "        \n",
    "    result = result[['PRMSIC', 'SICD', 'PNACODE', 'PNATITL', 'NAICS_LABEL', 'SHP_BOROUGH', 'SHP_CENSUS_TRACT', 'lmi_ct', \\\n",
    "                 'EMPSDT_SUM', 'EMPSDT_MED', 'SLSVDT_SUM', 'SLSVDT_MED', 'count_SUM', 'NTAName', 'Shape_Area', 'geometry', 'cluster']]\n",
    "    \n",
    "    result.columns = ['PRMSIC', 'SICD', 'PNACODE', 'PNATITL', 'NAICS', 'Borough', 'Census_Tract', \\\n",
    "                  'Median_Income_ct', 'EMPSDT_Sum', 'EMPSDT_Median', 'SLSVDT_Sum', 'SLSVDT_Median', \\\n",
    "                  'Business_Count', 'Neighborhood_Name', 'Shape_Area', 'geometry', 'cluster']\n",
    "    \n",
    "    result.loc[:,'geometry'] = result.apply(convertCoordinates, axis = 1)\n",
    "    geojson_string = gp.GeoDataFrame(result).to_json()\n",
    "    geojson_dict = json.loads( eojson_string)\n",
    "    loc = pnatitl_loc + \"/\" + sicd_file_name + \".geojson\"\n",
    "    \n",
    "    with open(loc, 'wb') as fp:\n",
    "        json.dump(geojson_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:21:21.133813\n"
     ]
    }
   ],
   "source": [
    "startTime = datetime.now()\n",
    "\n",
    "for index in range(cnt): \n",
    "    \n",
    "    year_dir = os.listdir(base_year_loc)\n",
    "    \n",
    "    naics = NAICS[index]\n",
    "    naics_dir_name = naics.replace(\"_\", \"\").replace(\", \", \"_\").replace(\" \", \"_\").replace(\"(\", \"\").\\\n",
    "    replace(\")\", \"\").lower()\n",
    "    \n",
    "    pnatitl = PNATITL[index]\n",
    "    pnatitl_dir_name = pnatitl.replace(\"/\", \"_\").replace(\" \", \"_\").replace(\"&\", \"and\")\\\n",
    "    .replace(\"(\", \"\").replace(\")\", \"\").replace(\",\", \"_\").replace(\"-\", \"_\").replace(\"'\",\"\").lower()\n",
    "    \n",
    "    sicd = SICD[index]\n",
    "    \n",
    "    if naics_dir_name not in os.listdir(base_year_loc): \n",
    "        naics_loc = base_year_loc + \"/\" + naics_dir_name\n",
    "        os.mkdir(naics_loc)\n",
    "        \n",
    "        pnatitl_loc = naics_loc + \"/\" + pnatitl_dir_name \n",
    "        os.mkdir(pnatitl_loc)\n",
    "        createGeoJSON(pnatitl_loc, sicd) \n",
    "\n",
    "        \n",
    "    else: \n",
    "        naics_loc = base_year_loc + \"/\" + naics_dir_name\n",
    "        \n",
    "        if pnatitl_dir_name not in os.listdir(naics_loc):\n",
    "            pnatitl_loc = naics_loc + \"/\" + pnatitl_dir_name \n",
    "            os.mkdir(pnatitl_loc)\n",
    "            createGeoJSON(pnatitl_loc, sicd) \n",
    "          \n",
    "        else: \n",
    "            pnatitl_loc = naics_loc + \"/\" + pnatitl_dir_name \n",
    "            createGeoJSON(pnatitl_loc, sicd) \n",
    "            \n",
    "print datetime.now() - startTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
